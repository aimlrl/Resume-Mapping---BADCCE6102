{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260},{"sourceId":14502473,"sourceType":"datasetVersion","datasetId":9262653}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pdfplumber\n!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:21:33.115000Z","iopub.execute_input":"2026-02-04T18:21:33.115358Z","iopub.status.idle":"2026-02-04T18:21:44.122223Z","shell.execute_reply.started":"2026-02-04T18:21:33.115327Z","shell.execute_reply":"2026-02-04T18:21:44.120967Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20251230 (from pdfplumber)\n  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\nDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.3.0\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pdfplumber\nfrom tqdm import tqdm\nimport tiktoken\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import BertTokenizerFast\nfrom torchinfo import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:20:47.800378Z","iopub.execute_input":"2026-02-04T19:20:47.800739Z","iopub.status.idle":"2026-02-04T19:20:47.834970Z","shell.execute_reply.started":"2026-02-04T19:20:47.800709Z","shell.execute_reply":"2026-02-04T19:20:47.833734Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:21:55.284207Z","iopub.execute_input":"2026-02-04T18:21:55.284681Z","iopub.status.idle":"2026-02-04T18:22:02.769394Z","shell.execute_reply.started":"2026-02-04T18:21:55.284647Z","shell.execute_reply":"2026-02-04T18:22:02.768252Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea129bf72e42494088a1b72355a2ee51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b4431662c1431088dbe2091fa75cc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66841459e809412ba9d8202518f730cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782e1c79fab64d1eb68b55ceabcbd908"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n\n    text = list()\n    with pdfplumber.open(pdf_path) as pdf:\n\n        for page in pdf.pages:\n            page_text = page.extract_text()\n\n            if page_text:\n                text.append(page_text)\n\n    return \"\\n\".join(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:02.771078Z","iopub.execute_input":"2026-02-04T18:22:02.771535Z","iopub.status.idle":"2026-02-04T18:22:02.777628Z","shell.execute_reply.started":"2026-02-04T18:22:02.771505Z","shell.execute_reply":"2026-02-04T18:22:02.776489Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_all_resumes(single_dir_abs_path):\n\n    documents = list()\n\n    for root,_,files in os.walk(single_dir_abs_path):\n        for file in files:\n            if file.lower().endswith(\".pdf\"):\n                pdf_path = os.path.join(root,file)\n                text = extract_text_from_pdf(pdf_path)\n                if text.strip():\n                    documents.append(text)\n    return documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:02.779578Z","iopub.execute_input":"2026-02-04T18:22:02.779950Z","iopub.status.idle":"2026-02-04T18:22:02.797408Z","shell.execute_reply.started":"2026-02-04T18:22:02.779918Z","shell.execute_reply":"2026-02-04T18:22:02.796237Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"root_dir = \"/kaggle/input/resume-dataset/data/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:02.798673Z","iopub.execute_input":"2026-02-04T18:22:02.799076Z","iopub.status.idle":"2026-02-04T18:22:02.816075Z","shell.execute_reply.started":"2026-02-04T18:22:02.799040Z","shell.execute_reply":"2026-02-04T18:22:02.814898Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def process_resumes_per_category(single_dir):\n    return single_dir, load_all_resumes(os.path.join(root_dir,single_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:02.817481Z","iopub.execute_input":"2026-02-04T18:22:02.817817Z","iopub.status.idle":"2026-02-04T18:22:02.835184Z","shell.execute_reply.started":"2026-02-04T18:22:02.817789Z","shell.execute_reply":"2026-02-04T18:22:02.834045Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\"\"\"\ndata_dict = dict()\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\n        try:\n            single_dir, resumes_raw_text_list = single_pool.result()\n            data_dict[single_dir] = resumes_raw_text_list\n        except Exception as e:\n            print(f\"Error processing {single_dir}: {e}\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:26:24.579754Z","iopub.execute_input":"2026-02-04T12:26:24.580718Z","iopub.status.idle":"2026-02-04T12:26:24.587643Z","shell.execute_reply.started":"2026-02-04T12:26:24.580673Z","shell.execute_reply":"2026-02-04T12:26:24.586745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\n    pickle.dump(data_dict,file_handle)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:26:27.740160Z","iopub.execute_input":"2026-02-04T12:26:27.740586Z","iopub.status.idle":"2026-02-04T12:26:27.747118Z","shell.execute_reply.started":"2026-02-04T12:26:27.740546Z","shell.execute_reply":"2026-02-04T12:26:27.746290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/proprocessed-data-pickle-file/data_dict.pkl\",\"rb\") as file_handle:\n    data_dict = pickle.load(file_handle)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:13.340376Z","iopub.execute_input":"2026-02-04T18:22:13.340714Z","iopub.status.idle":"2026-02-04T18:22:13.574919Z","shell.execute_reply.started":"2026-02-04T18:22:13.340685Z","shell.execute_reply":"2026-02-04T18:22:13.573856Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"bert_base_context_len = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:14.753079Z","iopub.execute_input":"2026-02-04T18:22:14.753458Z","iopub.status.idle":"2026-02-04T18:22:14.758069Z","shell.execute_reply.started":"2026-02-04T18:22:14.753427Z","shell.execute_reply":"2026-02-04T18:22:14.756849Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"resume_text = list()\nlabel = list()\n\nfor k,v in data_dict.items():\n    for single_resume_text in v:\n        \n        resume_text.append(single_resume_text)\n        label.append(k)\n\ndata = pd.DataFrame(data={\"Resume Text\":resume_text,\"Label\":label})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:16.476414Z","iopub.execute_input":"2026-02-04T18:22:16.476800Z","iopub.status.idle":"2026-02-04T18:22:16.488596Z","shell.execute_reply.started":"2026-02-04T18:22:16.476768Z","shell.execute_reply":"2026-02-04T18:22:16.487445Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"labels2idx = dict(zip(data_dict.keys(),range(0,len(data_dict.keys()))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:18.246713Z","iopub.execute_input":"2026-02-04T18:22:18.247751Z","iopub.status.idle":"2026-02-04T18:22:18.252288Z","shell.execute_reply.started":"2026-02-04T18:22:18.247712Z","shell.execute_reply":"2026-02-04T18:22:18.251372Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:19.126251Z","iopub.execute_input":"2026-02-04T18:22:19.127202Z","iopub.status.idle":"2026-02-04T18:22:19.152918Z","shell.execute_reply.started":"2026-02-04T18:22:19.127155Z","shell.execute_reply":"2026-02-04T18:22:19.152131Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                         Resume Text     Label\n0  PRE-PRESS GRAPHIC DESIGNER\\nSummary\\nCreative,...  DESIGNER\n1  PRINCIPLE DESIGNER / OWNER\\nProfessional Summa...  DESIGNER\n2  PROJECT DESIGNER\\nSummary\\nTeam-oriented and c...  DESIGNER\n3  INTERIOR DESIGNER\\nSummary\\nA results oriented...  DESIGNER\n4  PRESENTATION DESIGNER\\nSummary\\nCustomer Servi...  DESIGNER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PRE-PRESS GRAPHIC DESIGNER\\nSummary\\nCreative,...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PRINCIPLE DESIGNER / OWNER\\nProfessional Summa...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PROJECT DESIGNER\\nSummary\\nTeam-oriented and c...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTERIOR DESIGNER\\nSummary\\nA results oriented...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PRESENTATION DESIGNER\\nSummary\\nCustomer Servi...</td>\n      <td>DESIGNER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"idxes = np.arange(data.shape[0])\nnp.random.shuffle(idxes)\nshuffled_data = data.iloc[idxes]\nshuffled_data.reset_index(drop=True,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:21.212250Z","iopub.execute_input":"2026-02-04T18:22:21.213518Z","iopub.status.idle":"2026-02-04T18:22:21.223728Z","shell.execute_reply.started":"2026-02-04T18:22:21.213463Z","shell.execute_reply":"2026-02-04T18:22:21.222430Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"shuffled_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:22.953099Z","iopub.execute_input":"2026-02-04T18:22:22.953483Z","iopub.status.idle":"2026-02-04T18:22:22.964356Z","shell.execute_reply.started":"2026-02-04T18:22:22.953451Z","shell.execute_reply":"2026-02-04T18:22:22.963458Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                            Resume Text                 Label\n0     SALES\\nSummary\\nDedicated security enforcement...                 SALES\n1     TIMESHARE SALES\\nSummary\\nI am extremely confi...                 SALES\n2     SIMULATOR TECHNICIAN\\nSummary\\nExperienced Ele...              AVIATION\n3     SENIOR DIGITAL PRODUCER/MULTIMEDIA SPECIALIST\\...         DIGITAL-MEDIA\n4     ACCOUNTANT\\nHighlights\\nMicrosoft Office : Int...            ACCOUNTANT\n...                                                 ...                   ...\n2478  TEACHER\\nSummary\\nHighly enthusiasticÂ ,motiva...               TEACHER\n2479  NEW BUSINESS DEVELOPMENT MANAGER\\nSummary\\nBUS...  BUSINESS-DEVELOPMENT\n2480  ACCOUNTANT I\\nSummary\\nFlexible A ccountant wh...            ACCOUNTANT\n2481  CUSTOMER SERVICE REP\\nCareer Focus\\nTo find a ...              AVIATION\n2482  ELECTRICIAN\\nProfessional Summary\\nTechnically...              AVIATION\n\n[2483 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SALES\\nSummary\\nDedicated security enforcement...</td>\n      <td>SALES</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TIMESHARE SALES\\nSummary\\nI am extremely confi...</td>\n      <td>SALES</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SIMULATOR TECHNICIAN\\nSummary\\nExperienced Ele...</td>\n      <td>AVIATION</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SENIOR DIGITAL PRODUCER/MULTIMEDIA SPECIALIST\\...</td>\n      <td>DIGITAL-MEDIA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ACCOUNTANT\\nHighlights\\nMicrosoft Office : Int...</td>\n      <td>ACCOUNTANT</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2478</th>\n      <td>TEACHER\\nSummary\\nHighly enthusiasticÂ ,motiva...</td>\n      <td>TEACHER</td>\n    </tr>\n    <tr>\n      <th>2479</th>\n      <td>NEW BUSINESS DEVELOPMENT MANAGER\\nSummary\\nBUS...</td>\n      <td>BUSINESS-DEVELOPMENT</td>\n    </tr>\n    <tr>\n      <th>2480</th>\n      <td>ACCOUNTANT I\\nSummary\\nFlexible A ccountant wh...</td>\n      <td>ACCOUNTANT</td>\n    </tr>\n    <tr>\n      <th>2481</th>\n      <td>CUSTOMER SERVICE REP\\nCareer Focus\\nTo find a ...</td>\n      <td>AVIATION</td>\n    </tr>\n    <tr>\n      <th>2482</th>\n      <td>ELECTRICIAN\\nProfessional Summary\\nTechnically...</td>\n      <td>AVIATION</td>\n    </tr>\n  </tbody>\n</table>\n<p>2483 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"max_chunks = 0\n\nfor single_resume_text in resume_text:\n    chunked_encoded_text = tokenizer(text=single_resume_text,max_length=512,truncation=True,\n                                return_overflowing_tokens=True,stride=256,\n                                return_tensors=\"pt\",padding=\"max_length\")\n\n    if len(chunked_encoded_text[\"input_ids\"]) > max_chunks:\n        max_chunks = len(chunked_encoded_text[\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:27.505517Z","iopub.execute_input":"2026-02-04T18:22:27.506875Z","iopub.status.idle":"2026-02-04T18:22:47.264845Z","shell.execute_reply.started":"2026-02-04T18:22:27.506825Z","shell.execute_reply":"2026-02-04T18:22:47.263800Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(max_chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:49.101799Z","iopub.execute_input":"2026-02-04T18:22:49.102175Z","iopub.status.idle":"2026-02-04T18:22:49.106896Z","shell.execute_reply.started":"2026-02-04T18:22:49.102141Z","shell.execute_reply":"2026-02-04T18:22:49.105929Z"}},"outputs":[{"name":"stdout","text":"25\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"data_dict = dict(shuffled_data)\nresume_text = data_dict[\"Resume Text\"]\nlabel = data_dict[\"Label\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:51.664856Z","iopub.execute_input":"2026-02-04T18:22:51.665277Z","iopub.status.idle":"2026-02-04T18:22:51.670693Z","shell.execute_reply.started":"2026-02-04T18:22:51.665244Z","shell.execute_reply":"2026-02-04T18:22:51.669712Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def training_data_generator():\n\n    for single_resume_text,y in zip(resume_text[0:2000],label[0:2000]):\n        chunked_encoded_text = tokenizer(text=single_resume_text,max_length=bert_base_context_len,\n                                         truncation=True,return_overflowing_tokens=True,\n                                         stride=256,return_tensors=\"pt\",padding=\"max_length\")\n\n        yield chunked_encoded_text[\"input_ids\"],torch.tensor(labels2idx[y])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:53.419556Z","iopub.execute_input":"2026-02-04T18:22:53.420438Z","iopub.status.idle":"2026-02-04T18:22:53.426053Z","shell.execute_reply.started":"2026-02-04T18:22:53.420397Z","shell.execute_reply":"2026-02-04T18:22:53.424944Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def testing_data_generator():\n\n    for single_resume_text,y in zip(resume_text[2000:],label[2000:]):\n        chunked_encoded_text = tokenizer(text=single_resume_text,\n                                         max_length=bert_base_context_len,\n                                        truncation=True,return_overflowing_tokens=True,\n                                        stride=256,return_tensors=\"pt\",padding=\"max_length\")\n        yield chunked_encoded_text[\"input_ids\"],torch.tensor(labels2idx[y])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T18:22:53.979630Z","iopub.execute_input":"2026-02-04T18:22:53.979966Z","iopub.status.idle":"2026-02-04T18:22:53.985630Z","shell.execute_reply.started":"2026-02-04T18:22:53.979936Z","shell.execute_reply":"2026-02-04T18:22:53.984590Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class SingleAttentionHead(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,sha_dim,masked,is_dropout,\n                dropout_probability):\n        super().__init__()\n\n        self.sha_dim = sha_dim\n        self.masked = masked\n        self.is_dropout = is_dropout\n\n        self.query_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.key_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                   out_features=sha_dim,bias=False)\n        if self.is_dropout:\n            self.single_head_attn_mask_dropout = torch.nn.Dropout(p=dropout_probability)\n            \n        self.value_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.softmax_activation = torch.nn.Softmax(dim=1)\n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        projected_query = self.query_projection_layer(query_embedding)\n        projected_key = self.key_projection_layer(key_embedding)\n        projected_value = self.value_projection_layer(value_embedding)\n\n        query_key_similarity_search = torch.matmul(projected_query,torch.transpose(projected_key,1,0))/torch.sqrt(torch.tensor([self.sha_dim]))\n\n        if self.masked:\n            query_key_similarity_search = torch.tril(query_key_similarity_search,0)\n            \n        query_key_soft_search = self.softmax_activation(query_key_similarity_search)\n\n        if self.is_dropout:\n            query_key_soft_search = self.single_head_attn_mask_dropout(query_key_soft_search)\n            \n        weighted_attn_embedding = torch.matmul(query_key_soft_search,projected_value)\n\n        return weighted_attn_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:08:22.473792Z","iopub.execute_input":"2026-02-04T19:08:22.474635Z","iopub.status.idle":"2026-02-04T19:08:22.483666Z","shell.execute_reply.started":"2026-02-04T19:08:22.474593Z","shell.execute_reply":"2026-02-04T19:08:22.482759Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"class MultiHeadAttentionLayer(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,num_attn_heads,masked,\n                is_dropout,dropout_probability):\n        super().__init__()\n        \n        sha_dim = value_embedding_dim//num_attn_heads\n        self.attn_heads = list()\n        \n        for _ in range(num_attn_heads):\n            self.attn_heads.append(SingleAttentionHead(query_key_embedding_dim,value_embedding_dim,\n                                       sha_dim,masked,is_dropout,dropout_probability))\n\n        self.mha_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                   out_features=value_embedding_dim,bias=False)\n        self.is_dropout = is_dropout\n\n        if self.is_dropout:\n            self.mha_dropout_layer = torch.nn.Dropout(p=dropout_probability) \n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        attn_heads_weighted_embeddings = list()\n\n        for single_attn_head in self.attn_heads:\n            attn_heads_weighted_embeddings.append(single_attn_head(query_embedding,key_embedding,\n                                                                  value_embedding))\n\n        mha_concatenated_embeddings = torch.cat(attn_heads_weighted_embeddings,dim=1)\n        mha_output = self.mha_projection_layer(mha_concatenated_embeddings)\n\n        if self.is_dropout:\n            mha_output = self.mha_dropout_layer(mha_output)\n        \n        return mha_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:08:16.080387Z","iopub.execute_input":"2026-02-04T19:08:16.080743Z","iopub.status.idle":"2026-02-04T19:08:16.089364Z","shell.execute_reply.started":"2026-02-04T19:08:16.080713Z","shell.execute_reply":"2026-02-04T19:08:16.088314Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"class EncoderLayer(torch.nn.Module):\n\n    def __init__(self,input_embedding_dim,num_attn_heads,is_dropout,dropout_probability,\n                is_pre_norm,ffn_projection_dim,ffn_activation):\n        super().__init__()\n\n        activation_functions = {\n            \"relu\": torch.nn.ReLU,\n            \"sigmoid\": torch.nn.Sigmoid,\n            \"tanh\": torch.nn.Tanh,\n            \"gelu\": torch.nn.GELU\n        }\n\n        self.is_dropout = is_dropout\n        self.is_pre_norm = is_pre_norm\n\n        self.mha_layer = MultiHeadAttentionLayer(input_embedding_dim,input_embedding_dim,\n                                                num_attn_heads,False,is_dropout,dropout_probability)\n        self.first_layer_norm = torch.nn.LayerNorm(input_embedding_dim)\n\n        if is_dropout:\n            self.first_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n            \n        self.ffn_inner_layer = torch.nn.Linear(in_features=input_embedding_dim,\n                                              out_features=ffn_projection_dim)\n        self.ffn_inner_activation = activation_functions[ffn_activation]()\n        self.ffn_output_layer = torch.nn.Linear(in_features=ffn_projection_dim,\n                                               out_features=input_embedding_dim)\n        self.second_layer_norm = torch.nn.LayerNorm(input_embedding_dim)\n\n        if is_dropout:\n            self.second_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n\n    \n    def forward(self,input_embedding):\n\n        mha_layer_out = self.mha_layer(input_embedding,input_embedding,input_embedding)\n\n        if self.is_pre_norm:\n            first_layer_norm_out = mha_layer_out + self.first_layer_norm(input_embedding)\n        else:\n            first_layer_norm_out = self.first_layer_norm(input_embedding + mha_layer_out)\n        \n        if self.is_dropout:\n            first_layer_norm_out = self.first_dropout_layer(first_layer_norm_out)\n            \n        higher_dim_projection = self.ffn_inner_layer(first_layer_norm_out)\n        higher_dim_projection = self.ffn_inner_activation(higher_dim_projection)\n        ffn_out = self.ffn_output_layer(higher_dim_projection)\n\n        if self.is_pre_norm:\n            encoder_layer_out = ffn_out + self.second_layer_norm(first_layer_norm_out)\n        else:\n            encoder_layer_out = self.second_layer_norm(first_layer_norm_out + ffn_out)\n\n        if self.is_dropout:\n            encoder_layer_out = self.second_dropout_layer(encoder_layer_out)\n\n        return encoder_layer_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:06:23.306837Z","iopub.execute_input":"2026-02-04T19:06:23.307245Z","iopub.status.idle":"2026-02-04T19:06:23.318554Z","shell.execute_reply.started":"2026-02-04T19:06:23.307213Z","shell.execute_reply":"2026-02-04T19:06:23.317606Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class BERT(torch.nn.Module):\n\n    def __init__(self,model_context_len,vocab_size,model_dim,num_encoder_layers,num_attn_heads,\n                dropout_probability,is_sequence_classification):\n        super().__init__()\n\n        self.model_context_len = model_context_len\n        self.is_sequence_classification = is_sequence_classification\n        self.token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n                                                  embedding_dim=model_dim)\n        self.pos_encoding_layer = torch.nn.Embedding(num_embeddings=model_context_len,\n                                                    embedding_dim=model_dim)\n        self.segment_embedding_layer = torch.nn.Embedding(num_embeddings=2,\n                                                          embedding_dim=model_dim)\n        self.embedding_sum_layer_norm = torch.nn.LayerNorm(model_dim)\n        self.first_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n        self.encoder_layer_stack = list()\n\n        for _ in range(num_encoder_layers):\n            self.encoder_layer_stack.append(EncoderLayer(model_dim,num_attn_heads,True,\n                                                         dropout_probability,False,4*model_dim,\n                                                         \"gelu\"))\n\n\n    def forward(self,X):\n\n        X = X.to(torch.int)\n        token_embedding = self.token_embedding_layer(X)\n        position_ids = torch.arange(start=0,end=self.model_context_len)\n        pos_encoding = self.pos_encoding_layer(position_ids)\n\n        if self.is_sequence_classification:\n            segment_ids = torch.zeros(self.model_context_len,)\n            \n        segment_encoding = self.segment_embedding_layer(segment_ids)\n        \n        input_embedding = token_embedding + pos_encoding + segment_embedding\n        input_embedding = self.embedding_sum_layer_norm(input_embedding)\n        input_embedding = self.first_droput_layer(input_embedding)\n\n        for single_encoding_layer in self.encoder_layer_stack:\n            output_embedding = single_encoding_layer(input_embedding)\n            input_embedding = output_embedding\n\n        return output_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:16:29.377931Z","iopub.execute_input":"2026-02-04T19:16:29.378324Z","iopub.status.idle":"2026-02-04T19:16:29.389776Z","shell.execute_reply.started":"2026-02-04T19:16:29.378292Z","shell.execute_reply":"2026-02-04T19:16:29.388405Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"my_bert_model = BERT(512,30522,768,12,12,0.1,True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T19:16:31.726191Z","iopub.execute_input":"2026-02-04T19:16:31.726533Z","iopub.status.idle":"2026-02-04T19:16:32.980076Z","shell.execute_reply.started":"2026-02-04T19:16:31.726502Z","shell.execute_reply":"2026-02-04T19:16:32.978891Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}