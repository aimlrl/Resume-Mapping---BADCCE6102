{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pdfplumber\n!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:43:07.987238Z","iopub.execute_input":"2026-01-15T02:43:07.987704Z","iopub.status.idle":"2026-01-15T02:43:19.326316Z","shell.execute_reply.started":"2026-01-15T02:43:07.987662Z","shell.execute_reply":"2026-01-15T02:43:19.325070Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20251230 (from pdfplumber)\n  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\nDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.3.0\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pdfplumber\nfrom tqdm import tqdm\nimport tiktoken\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:46:48.794283Z","iopub.execute_input":"2026-01-15T02:46:48.794678Z","iopub.status.idle":"2026-01-15T02:46:49.045216Z","shell.execute_reply.started":"2026-01-15T02:46:48.794631Z","shell.execute_reply":"2026-01-15T02:46:49.043817Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n\n    text = list()\n    with pdfplumber.open(pdf_path) as pdf:\n\n        for page in pdf.pages:\n            page_text = page.extract_text()\n\n            if page_text:\n                text.append(page_text)\n\n    return \"\\n\".join(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:46:55.915304Z","iopub.execute_input":"2026-01-15T02:46:55.915848Z","iopub.status.idle":"2026-01-15T02:46:55.921735Z","shell.execute_reply.started":"2026-01-15T02:46:55.915818Z","shell.execute_reply":"2026-01-15T02:46:55.920578Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def load_all_resumes(single_dir_abs_path):\n\n    documents = list()\n\n    #for single_dir in tqdm(os.listdir(root_dir)):\n    #for root,_,files in os.walk(os.path.join(root_dir,single_dir)):\n    for root,_,files in os.walk(single_dir_abs_path):\n        for file in files:\n            if file.lower().endswith(\".pdf\"):\n                pdf_path = os.path.join(root,file)\n                text = extract_text_from_pdf(pdf_path)\n                if text.strip():\n                    documents.append(text)\n    return documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:47:38.642175Z","iopub.execute_input":"2026-01-15T02:47:38.642496Z","iopub.status.idle":"2026-01-15T02:47:38.652222Z","shell.execute_reply.started":"2026-01-15T02:47:38.642470Z","shell.execute_reply":"2026-01-15T02:47:38.651151Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"root_dir = \"/kaggle/input/resume-dataset/data/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:47:40.814117Z","iopub.execute_input":"2026-01-15T02:47:40.814436Z","iopub.status.idle":"2026-01-15T02:47:40.819354Z","shell.execute_reply.started":"2026-01-15T02:47:40.814409Z","shell.execute_reply":"2026-01-15T02:47:40.818266Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def process_resumes_per_category(single_dir):\n    return single_dir, load_all_resumes(os.path.join(root_dir,single_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:47:53.731178Z","iopub.execute_input":"2026-01-15T02:47:53.731469Z","iopub.status.idle":"2026-01-15T02:47:53.736960Z","shell.execute_reply.started":"2026-01-15T02:47:53.731445Z","shell.execute_reply":"2026-01-15T02:47:53.735856Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\"\"\"\ndata_dict = dict()\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\n        try:\n            single_dir, resumes_raw_text_list = single_pool.result()\n            data_dict[single_dir] = resumes_raw_text_list\n        except Exception as e:\n            print(f\"Error processing {single_dir}: {e}\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:50:26.956367Z","iopub.execute_input":"2026-01-15T02:50:26.956740Z","iopub.status.idle":"2026-01-15T02:50:26.964550Z","shell.execute_reply.started":"2026-01-15T02:50:26.956714Z","shell.execute_reply":"2026-01-15T02:50:26.963600Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'\\ndata_dict = dict()\\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\\n    \\n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\\n        try:\\n            single_dir, resumes_raw_text_list = single_pool.result()\\n            data_dict[single_dir] = resumes_raw_text_list\\n        except Exception as e:\\n            print(f\"Error processing {single_dir}: {e}\")\\n'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"gpt_tokenizer_encodings = tiktoken.get_encoding(\"o200k_base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:48:21.566912Z","iopub.execute_input":"2026-01-15T02:48:21.567219Z","iopub.status.idle":"2026-01-15T02:48:25.664060Z","shell.execute_reply.started":"2026-01-15T02:48:21.567196Z","shell.execute_reply":"2026-01-15T02:48:25.663143Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\"\"\"\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\n    pickle.dump(data_dict,file_handle)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-15T02:50:29.258876Z","iopub.execute_input":"2026-01-15T02:50:29.259229Z","iopub.status.idle":"2026-01-15T02:50:29.265732Z","shell.execute_reply.started":"2026-01-15T02:50:29.259202Z","shell.execute_reply":"2026-01-15T02:50:29.264619Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\\n    pickle.dump(data_dict,file_handle)\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"data = pd.DataFrame(data={\"Resume Encoded Text\":None, \"Suitable Job\":None)}\n\nfor k,v in data_dict.items():\n    for resume_text in v:\n\n        data[\"Resume Encoded Text\"] = gpt_tokenizer_enc.enccode(resume_text)\n        data[\"Suitable Job\"] = k","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_data = data.iloc[0:int(0.7*data.shape[0])]\ntesting_data = data.iloc[int(0.7*data.shape[0])]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels2idx = dict(zip(data_dict.keys(),range(0,len(data_dict.keys()))))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def training_data_generator(mb_size=10):\n\n    for i in range(training_data.shape[0]//mb_size):\n\n        X_train_mb = np.array(data.iloc[i*mb_size:(i+1)*mb_size])\n        y_train_mb = np.array(data.iloc[i*mb_size:(i+1)*mb_size].map(labels2idx))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}