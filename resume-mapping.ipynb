{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260},{"sourceId":14502473,"sourceType":"datasetVersion","datasetId":9262653}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pdfplumber\n!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:13:28.249539Z","iopub.execute_input":"2026-02-05T19:13:28.250283Z","iopub.status.idle":"2026-02-05T19:13:39.337137Z","shell.execute_reply.started":"2026-02-05T19:13:28.250215Z","shell.execute_reply":"2026-02-05T19:13:39.335961Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20251230 (from pdfplumber)\n  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\nDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.3.0\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pdfplumber\nfrom tqdm import tqdm\nimport tiktoken\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import BertTokenizerFast, BertConfig, BertModel\nfrom torchinfo import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:13:52.644773Z","iopub.execute_input":"2026-02-05T19:13:52.645728Z","iopub.status.idle":"2026-02-05T19:14:29.621328Z","shell.execute_reply.started":"2026-02-05T19:13:52.645685Z","shell.execute_reply":"2026-02-05T19:14:29.620319Z"}},"outputs":[{"name":"stderr","text":"2026-02-05 19:14:11.934569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770318852.200915      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770318852.280570      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770318852.959097      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770318852.959147      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770318852.959150      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770318852.959153      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:14:40.589707Z","iopub.execute_input":"2026-02-05T19:14:40.590416Z","iopub.status.idle":"2026-02-05T19:14:44.224586Z","shell.execute_reply.started":"2026-02-05T19:14:40.590382Z","shell.execute_reply":"2026-02-05T19:14:44.223641Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8ad91c460a44a0b84d4f6b11c9f8397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbb8966972d49fca415d8da41046946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7e47e56d58d455fbd898fecad3b7186"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2f898edf83d41b48ccab09610811f85"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n\n    text = list()\n    with pdfplumber.open(pdf_path) as pdf:\n\n        for page in pdf.pages:\n            page_text = page.extract_text()\n\n            if page_text:\n                text.append(page_text)\n\n    return \"\\n\".join(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:14:49.905532Z","iopub.execute_input":"2026-02-05T19:14:49.906467Z","iopub.status.idle":"2026-02-05T19:14:49.912130Z","shell.execute_reply.started":"2026-02-05T19:14:49.906432Z","shell.execute_reply":"2026-02-05T19:14:49.911125Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_all_resumes(single_dir_abs_path):\n\n    documents = list()\n\n    for root,_,files in os.walk(single_dir_abs_path):\n        for file in files:\n            if file.lower().endswith(\".pdf\"):\n                pdf_path = os.path.join(root,file)\n                text = extract_text_from_pdf(pdf_path)\n                if text.strip():\n                    documents.append(text)\n    return documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:14:59.672225Z","iopub.execute_input":"2026-02-05T19:14:59.672541Z","iopub.status.idle":"2026-02-05T19:14:59.678145Z","shell.execute_reply.started":"2026-02-05T19:14:59.672515Z","shell.execute_reply":"2026-02-05T19:14:59.677176Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"root_dir = \"/kaggle/input/resume-dataset/data/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:01.606568Z","iopub.execute_input":"2026-02-05T19:15:01.606977Z","iopub.status.idle":"2026-02-05T19:15:01.611513Z","shell.execute_reply.started":"2026-02-05T19:15:01.606937Z","shell.execute_reply":"2026-02-05T19:15:01.610406Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def process_resumes_per_category(single_dir):\n    return single_dir, load_all_resumes(os.path.join(root_dir,single_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:02.801522Z","iopub.execute_input":"2026-02-05T19:15:02.802444Z","iopub.status.idle":"2026-02-05T19:15:02.806618Z","shell.execute_reply.started":"2026-02-05T19:15:02.802409Z","shell.execute_reply":"2026-02-05T19:15:02.805559Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\"\"\"\ndata_dict = dict()\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\n        try:\n            single_dir, resumes_raw_text_list = single_pool.result()\n            data_dict[single_dir] = resumes_raw_text_list\n        except Exception as e:\n            print(f\"Error processing {single_dir}: {e}\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:26:24.579754Z","iopub.execute_input":"2026-02-04T12:26:24.580718Z","iopub.status.idle":"2026-02-04T12:26:24.587643Z","shell.execute_reply.started":"2026-02-04T12:26:24.580673Z","shell.execute_reply":"2026-02-04T12:26:24.586745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\n    pickle.dump(data_dict,file_handle)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T12:26:27.740160Z","iopub.execute_input":"2026-02-04T12:26:27.740586Z","iopub.status.idle":"2026-02-04T12:26:27.747118Z","shell.execute_reply.started":"2026-02-04T12:26:27.740546Z","shell.execute_reply":"2026-02-04T12:26:27.746290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/proprocessed-data-pickle-file/data_dict.pkl\",\"rb\") as file_handle:\n    data_dict = pickle.load(file_handle)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:06.289058Z","iopub.execute_input":"2026-02-05T19:15:06.289995Z","iopub.status.idle":"2026-02-05T19:15:06.385412Z","shell.execute_reply.started":"2026-02-05T19:15:06.289949Z","shell.execute_reply":"2026-02-05T19:15:06.384432Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"bert_base_context_len = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:07.566263Z","iopub.execute_input":"2026-02-05T19:15:07.566979Z","iopub.status.idle":"2026-02-05T19:15:07.571032Z","shell.execute_reply.started":"2026-02-05T19:15:07.566925Z","shell.execute_reply":"2026-02-05T19:15:07.570006Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"resume_text = list()\nlabel = list()\n\nfor k,v in data_dict.items():\n    for single_resume_text in v:\n        \n        resume_text.append(single_resume_text)\n        label.append(k)\n\ndata = pd.DataFrame(data={\"Resume Text\":resume_text,\"Label\":label})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:09.193595Z","iopub.execute_input":"2026-02-05T19:15:09.194619Z","iopub.status.idle":"2026-02-05T19:15:09.206667Z","shell.execute_reply.started":"2026-02-05T19:15:09.194584Z","shell.execute_reply":"2026-02-05T19:15:09.205654Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"labels2idx = dict(zip(data_dict.keys(),range(0,len(data_dict.keys()))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:15.289248Z","iopub.execute_input":"2026-02-05T19:15:15.289990Z","iopub.status.idle":"2026-02-05T19:15:15.294606Z","shell.execute_reply.started":"2026-02-05T19:15:15.289934Z","shell.execute_reply":"2026-02-05T19:15:15.293485Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:20.104366Z","iopub.execute_input":"2026-02-05T19:15:20.105548Z","iopub.status.idle":"2026-02-05T19:15:20.130754Z","shell.execute_reply.started":"2026-02-05T19:15:20.105511Z","shell.execute_reply":"2026-02-05T19:15:20.130003Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                         Resume Text     Label\n0  PRE-PRESS GRAPHIC DESIGNER\\nSummary\\nCreative,...  DESIGNER\n1  PRINCIPLE DESIGNER / OWNER\\nProfessional Summa...  DESIGNER\n2  PROJECT DESIGNER\\nSummary\\nTeam-oriented and c...  DESIGNER\n3  INTERIOR DESIGNER\\nSummary\\nA results oriented...  DESIGNER\n4  PRESENTATION DESIGNER\\nSummary\\nCustomer Servi...  DESIGNER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>PRE-PRESS GRAPHIC DESIGNER\\nSummary\\nCreative,...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PRINCIPLE DESIGNER / OWNER\\nProfessional Summa...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PROJECT DESIGNER\\nSummary\\nTeam-oriented and c...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>INTERIOR DESIGNER\\nSummary\\nA results oriented...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PRESENTATION DESIGNER\\nSummary\\nCustomer Servi...</td>\n      <td>DESIGNER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"idxes = np.arange(data.shape[0])\nnp.random.shuffle(idxes)\nshuffled_data = data.iloc[idxes]\nshuffled_data.reset_index(drop=True,inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:21.894341Z","iopub.execute_input":"2026-02-05T19:15:21.894997Z","iopub.status.idle":"2026-02-05T19:15:21.905293Z","shell.execute_reply.started":"2026-02-05T19:15:21.894950Z","shell.execute_reply":"2026-02-05T19:15:21.904152Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"shuffled_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:29.654576Z","iopub.execute_input":"2026-02-05T19:15:29.655139Z","iopub.status.idle":"2026-02-05T19:15:29.664277Z","shell.execute_reply.started":"2026-02-05T19:15:29.655102Z","shell.execute_reply":"2026-02-05T19:15:29.663340Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                         Resume Text         Label\n0  CONSULTANT\\nObjective\\nEnthusiastic Pharmacist...    CONSULTANT\n1  SALES\\nExecutive Summary\\nTwenty years of expe...         SALES\n2  ELECTRONIC TECHNICIAN II\\nProfile\\nTo acquire ...  CONSTRUCTION\n3  Karla Lee\\nSummary\\nResults-focused people adv...       BANKING\n4  DOCUMENT CONTROLLER (CONTRACT POSITION)\\nSumma...       APPAREL","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Text</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CONSULTANT\\nObjective\\nEnthusiastic Pharmacist...</td>\n      <td>CONSULTANT</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SALES\\nExecutive Summary\\nTwenty years of expe...</td>\n      <td>SALES</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ELECTRONIC TECHNICIAN II\\nProfile\\nTo acquire ...</td>\n      <td>CONSTRUCTION</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Karla Lee\\nSummary\\nResults-focused people adv...</td>\n      <td>BANKING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>DOCUMENT CONTROLLER (CONTRACT POSITION)\\nSumma...</td>\n      <td>APPAREL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"max_chunks = 0\n\nfor single_resume_text in resume_text:\n    chunked_encoded_text = tokenizer(text=single_resume_text,max_length=512,truncation=True,\n                                return_overflowing_tokens=True,stride=256,\n                                return_tensors=\"pt\",padding=\"max_length\")\n\n    if len(chunked_encoded_text[\"input_ids\"]) > max_chunks:\n        max_chunks = len(chunked_encoded_text[\"input_ids\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:15:32.249503Z","iopub.execute_input":"2026-02-05T19:15:32.250026Z","iopub.status.idle":"2026-02-05T19:15:50.274090Z","shell.execute_reply.started":"2026-02-05T19:15:32.249991Z","shell.execute_reply":"2026-02-05T19:15:50.273255Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print(max_chunks)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:08.833398Z","iopub.execute_input":"2026-02-05T19:16:08.834800Z","iopub.status.idle":"2026-02-05T19:16:08.840028Z","shell.execute_reply.started":"2026-02-05T19:16:08.834746Z","shell.execute_reply":"2026-02-05T19:16:08.839023Z"}},"outputs":[{"name":"stdout","text":"25\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"data_dict = dict(shuffled_data)\nresume_text = data_dict[\"Resume Text\"]\nlabel = data_dict[\"Label\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:10.686201Z","iopub.execute_input":"2026-02-05T19:16:10.687160Z","iopub.status.idle":"2026-02-05T19:16:10.691754Z","shell.execute_reply.started":"2026-02-05T19:16:10.687127Z","shell.execute_reply":"2026-02-05T19:16:10.690697Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def training_data_generator():\n\n    for single_resume_text,y in zip(resume_text[0:2000],label[0:2000]):\n        chunked_encoded_text = tokenizer(text=single_resume_text,max_length=bert_base_context_len,\n                                         truncation=True,return_overflowing_tokens=True,\n                                         stride=256,return_tensors=\"pt\",padding=\"max_length\")\n\n        yield chunked_encoded_text[\"input_ids\"],torch.tensor(labels2idx[y])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:12.339754Z","iopub.execute_input":"2026-02-05T19:16:12.340279Z","iopub.status.idle":"2026-02-05T19:16:12.345901Z","shell.execute_reply.started":"2026-02-05T19:16:12.340243Z","shell.execute_reply":"2026-02-05T19:16:12.344966Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def testing_data_generator():\n\n    for single_resume_text,y in zip(resume_text[2000:],label[2000:]):\n        chunked_encoded_text = tokenizer(text=single_resume_text,\n                                         max_length=bert_base_context_len,\n                                        truncation=True,return_overflowing_tokens=True,\n                                        stride=256,return_tensors=\"pt\",padding=\"max_length\")\n        yield chunked_encoded_text[\"input_ids\"],torch.tensor(labels2idx[y])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:13.979759Z","iopub.execute_input":"2026-02-05T19:16:13.980268Z","iopub.status.idle":"2026-02-05T19:16:13.986253Z","shell.execute_reply.started":"2026-02-05T19:16:13.980235Z","shell.execute_reply":"2026-02-05T19:16:13.985100Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class SingleAttentionHead(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,sha_dim,masked,is_dropout,\n                dropout_probability):\n        super().__init__()\n\n        self.sha_dim = sha_dim\n        self.masked = masked\n        self.is_dropout = is_dropout\n\n        self.query_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.key_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                   out_features=sha_dim,bias=False)\n        if self.is_dropout:\n            self.single_head_attn_mask_dropout = torch.nn.Dropout(p=dropout_probability)\n            \n        self.value_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.softmax_activation = torch.nn.Softmax(dim=1)\n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        projected_query = self.query_projection_layer(query_embedding)\n        projected_key = self.key_projection_layer(key_embedding)\n        projected_value = self.value_projection_layer(value_embedding)\n\n        query_key_similarity_search = torch.matmul(projected_query,torch.transpose(projected_key,1,0))/torch.sqrt(torch.tensor([self.sha_dim]))\n\n        if self.masked:\n            query_key_similarity_search = torch.tril(query_key_similarity_search,0)\n            \n        query_key_soft_search = self.softmax_activation(query_key_similarity_search)\n\n        if self.is_dropout:\n            query_key_soft_search = self.single_head_attn_mask_dropout(query_key_soft_search)\n            \n        weighted_attn_embedding = torch.matmul(query_key_soft_search,projected_value)\n\n        return weighted_attn_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:16.720271Z","iopub.execute_input":"2026-02-05T19:16:16.720907Z","iopub.status.idle":"2026-02-05T19:16:16.729965Z","shell.execute_reply.started":"2026-02-05T19:16:16.720850Z","shell.execute_reply":"2026-02-05T19:16:16.729003Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class MultiHeadAttentionLayer(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,num_attn_heads,masked,\n                is_dropout,dropout_probability):\n        super().__init__()\n        \n        sha_dim = value_embedding_dim//num_attn_heads\n        attn_heads = list()\n        \n        for _ in range(num_attn_heads):\n            attn_heads.append(SingleAttentionHead(query_key_embedding_dim,value_embedding_dim,\n                                       sha_dim,masked,is_dropout,dropout_probability))\n\n        self.attn_heads = torch.nn.ModuleList(attn_heads)\n\n        self.mha_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                   out_features=value_embedding_dim,bias=False)\n        self.is_dropout = is_dropout\n\n        if self.is_dropout:\n            self.mha_dropout_layer = torch.nn.Dropout(p=dropout_probability) \n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        attn_heads_weighted_embeddings = list()\n\n        for single_attn_head in self.attn_heads:\n            attn_heads_weighted_embeddings.append(single_attn_head(query_embedding,key_embedding,\n                                                                  value_embedding))\n\n        mha_concatenated_embeddings = torch.cat(attn_heads_weighted_embeddings,dim=1)\n        mha_output = self.mha_projection_layer(mha_concatenated_embeddings)\n\n        if self.is_dropout:\n            mha_output = self.mha_dropout_layer(mha_output)\n        \n        return mha_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:18.526948Z","iopub.execute_input":"2026-02-05T19:16:18.528029Z","iopub.status.idle":"2026-02-05T19:16:18.535249Z","shell.execute_reply.started":"2026-02-05T19:16:18.527993Z","shell.execute_reply":"2026-02-05T19:16:18.534362Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class EncoderLayer(torch.nn.Module):\n\n    def __init__(self,input_embedding_dim,num_attn_heads,is_dropout,dropout_probability,\n                is_pre_norm,ffn_projection_dim,ffn_activation):\n        super().__init__()\n\n        activation_functions = {\n            \"relu\": torch.nn.ReLU,\n            \"sigmoid\": torch.nn.Sigmoid,\n            \"tanh\": torch.nn.Tanh,\n            \"gelu\": torch.nn.GELU\n        }\n\n        self.is_dropout = is_dropout\n        self.is_pre_norm = is_pre_norm\n\n        self.mha_layer = MultiHeadAttentionLayer(input_embedding_dim,input_embedding_dim,\n                                                num_attn_heads,False,is_dropout,dropout_probability)\n        self.first_layer_norm = torch.nn.LayerNorm(input_embedding_dim)\n\n        if is_dropout:\n            self.first_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n            \n        self.ffn_inner_layer = torch.nn.Linear(in_features=input_embedding_dim,\n                                              out_features=ffn_projection_dim)\n        self.ffn_inner_activation = activation_functions[ffn_activation]()\n        self.ffn_output_layer = torch.nn.Linear(in_features=ffn_projection_dim,\n                                               out_features=input_embedding_dim)\n        self.second_layer_norm = torch.nn.LayerNorm(input_embedding_dim)\n\n        if is_dropout:\n            self.second_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n\n    \n    def forward(self,input_embedding):\n\n        mha_layer_out = self.mha_layer(input_embedding,input_embedding,input_embedding)\n\n        if self.is_pre_norm:\n            first_layer_norm_out = mha_layer_out + self.first_layer_norm(input_embedding)\n        else:\n            first_layer_norm_out = self.first_layer_norm(input_embedding + mha_layer_out)\n        \n        if self.is_dropout:\n            first_layer_norm_out = self.first_dropout_layer(first_layer_norm_out)\n            \n        higher_dim_projection = self.ffn_inner_layer(first_layer_norm_out)\n        higher_dim_projection = self.ffn_inner_activation(higher_dim_projection)\n        ffn_out = self.ffn_output_layer(higher_dim_projection)\n\n        if self.is_pre_norm:\n            encoder_layer_out = ffn_out + self.second_layer_norm(first_layer_norm_out)\n        else:\n            encoder_layer_out = self.second_layer_norm(first_layer_norm_out + ffn_out)\n\n        if self.is_dropout:\n            encoder_layer_out = self.second_dropout_layer(encoder_layer_out)\n\n        return encoder_layer_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:27.817080Z","iopub.execute_input":"2026-02-05T19:16:27.817955Z","iopub.status.idle":"2026-02-05T19:16:27.827820Z","shell.execute_reply.started":"2026-02-05T19:16:27.817906Z","shell.execute_reply":"2026-02-05T19:16:27.827153Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class BERT(torch.nn.Module):\n\n    def __init__(self,model_context_len,vocab_size,model_dim,num_encoder_layers,num_attn_heads,\n                dropout_probability,is_sequence_classification):\n        super().__init__()\n\n        self.model_context_len = model_context_len\n        self.is_sequence_classification = is_sequence_classification\n        self.token_embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n                                                  embedding_dim=model_dim)\n        self.pos_encoding_layer = torch.nn.Embedding(num_embeddings=model_context_len,\n                                                    embedding_dim=model_dim)\n        self.segment_embedding_layer = torch.nn.Embedding(num_embeddings=2,\n                                                          embedding_dim=model_dim)\n        self.embedding_sum_layer_norm = torch.nn.LayerNorm(model_dim)\n        self.first_dropout_layer = torch.nn.Dropout(p=dropout_probability)\n        encoder_layer_stack = list()\n\n        for _ in range(num_encoder_layers):\n            encoder_layer_stack.append(EncoderLayer(model_dim,num_attn_heads,True,\n                                                         dropout_probability,False,4*model_dim,\n                                                         \"gelu\"))\n        self.encoder_layer_stack = torch.nn.ModuleList(encoder_layer_stack)\n\n\n    def forward(self,X):\n\n        X = X.to(torch.int)\n        token_embedding = self.token_embedding_layer(X)\n\n        position_ids = torch.arange(start=0,end=self.model_context_len,dtype=torch.int)\n        pos_encoding = self.pos_encoding_layer(position_ids)\n\n        if self.is_sequence_classification:\n            segment_ids = torch.zeros(self.model_context_len,dtype=torch.int)\n            \n        segment_embedding = self.segment_embedding_layer(segment_ids)\n        \n        input_embedding = token_embedding + pos_encoding + segment_embedding\n        input_embedding = self.embedding_sum_layer_norm(input_embedding)\n        input_embedding = self.first_dropout_layer(input_embedding)\n\n        output_embedding = input_embedding\n        \n        for single_encoding_layer in self.encoder_layer_stack:\n            output_embedding = single_encoding_layer(output_embedding)\n\n        return output_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:36.127729Z","iopub.execute_input":"2026-02-05T19:16:36.128486Z","iopub.status.idle":"2026-02-05T19:16:36.138703Z","shell.execute_reply.started":"2026-02-05T19:16:36.128446Z","shell.execute_reply":"2026-02-05T19:16:36.137774Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"my_bert_model = BERT(512,30522,768,12,12,0.1,True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:38.315611Z","iopub.execute_input":"2026-02-05T19:16:38.315947Z","iopub.status.idle":"2026-02-05T19:16:39.377449Z","shell.execute_reply.started":"2026-02-05T19:16:38.315920Z","shell.execute_reply":"2026-02-05T19:16:39.376738Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"summary(model=my_bert_model,input_size=(512,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:16:54.593382Z","iopub.execute_input":"2026-02-05T19:16:54.594460Z","iopub.status.idle":"2026-02-05T19:16:55.881948Z","shell.execute_reply.started":"2026-02-05T19:16:54.594416Z","shell.execute_reply":"2026-02-05T19:16:55.880960Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"=========================================================================================================\nLayer (type:depth-idx)                                  Output Shape              Param #\n=========================================================================================================\nBERT                                                    [512, 768]                --\n├─Embedding: 1-1                                        [512, 768]                23,440,896\n├─Embedding: 1-2                                        [512, 768]                393,216\n├─Embedding: 1-3                                        [512, 768]                1,536\n├─LayerNorm: 1-4                                        [512, 768]                1,536\n├─Dropout: 1-5                                          [512, 768]                --\n├─ModuleList: 1-6                                       --                        --\n│    └─EncoderLayer: 2-1                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-1                [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-2                              [512, 768]                1,536\n│    │    └─Dropout: 3-3                                [512, 768]                --\n│    │    └─Linear: 3-4                                 [512, 3072]               2,362,368\n│    │    └─GELU: 3-5                                   [512, 3072]               --\n│    │    └─Linear: 3-6                                 [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-7                              [512, 768]                1,536\n│    │    └─Dropout: 3-8                                [512, 768]                --\n│    └─EncoderLayer: 2-2                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-9                [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-10                             [512, 768]                1,536\n│    │    └─Dropout: 3-11                               [512, 768]                --\n│    │    └─Linear: 3-12                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-13                                  [512, 3072]               --\n│    │    └─Linear: 3-14                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-15                             [512, 768]                1,536\n│    │    └─Dropout: 3-16                               [512, 768]                --\n│    └─EncoderLayer: 2-3                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-17               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-18                             [512, 768]                1,536\n│    │    └─Dropout: 3-19                               [512, 768]                --\n│    │    └─Linear: 3-20                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-21                                  [512, 3072]               --\n│    │    └─Linear: 3-22                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-23                             [512, 768]                1,536\n│    │    └─Dropout: 3-24                               [512, 768]                --\n│    └─EncoderLayer: 2-4                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-25               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-26                             [512, 768]                1,536\n│    │    └─Dropout: 3-27                               [512, 768]                --\n│    │    └─Linear: 3-28                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-29                                  [512, 3072]               --\n│    │    └─Linear: 3-30                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-31                             [512, 768]                1,536\n│    │    └─Dropout: 3-32                               [512, 768]                --\n│    └─EncoderLayer: 2-5                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-33               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-34                             [512, 768]                1,536\n│    │    └─Dropout: 3-35                               [512, 768]                --\n│    │    └─Linear: 3-36                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-37                                  [512, 3072]               --\n│    │    └─Linear: 3-38                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-39                             [512, 768]                1,536\n│    │    └─Dropout: 3-40                               [512, 768]                --\n│    └─EncoderLayer: 2-6                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-41               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-42                             [512, 768]                1,536\n│    │    └─Dropout: 3-43                               [512, 768]                --\n│    │    └─Linear: 3-44                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-45                                  [512, 3072]               --\n│    │    └─Linear: 3-46                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-47                             [512, 768]                1,536\n│    │    └─Dropout: 3-48                               [512, 768]                --\n│    └─EncoderLayer: 2-7                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-49               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-50                             [512, 768]                1,536\n│    │    └─Dropout: 3-51                               [512, 768]                --\n│    │    └─Linear: 3-52                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-53                                  [512, 3072]               --\n│    │    └─Linear: 3-54                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-55                             [512, 768]                1,536\n│    │    └─Dropout: 3-56                               [512, 768]                --\n│    └─EncoderLayer: 2-8                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-57               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-58                             [512, 768]                1,536\n│    │    └─Dropout: 3-59                               [512, 768]                --\n│    │    └─Linear: 3-60                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-61                                  [512, 3072]               --\n│    │    └─Linear: 3-62                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-63                             [512, 768]                1,536\n│    │    └─Dropout: 3-64                               [512, 768]                --\n│    └─EncoderLayer: 2-9                                [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-65               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-66                             [512, 768]                1,536\n│    │    └─Dropout: 3-67                               [512, 768]                --\n│    │    └─Linear: 3-68                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-69                                  [512, 3072]               --\n│    │    └─Linear: 3-70                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-71                             [512, 768]                1,536\n│    │    └─Dropout: 3-72                               [512, 768]                --\n│    └─EncoderLayer: 2-10                               [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-73               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-74                             [512, 768]                1,536\n│    │    └─Dropout: 3-75                               [512, 768]                --\n│    │    └─Linear: 3-76                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-77                                  [512, 3072]               --\n│    │    └─Linear: 3-78                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-79                             [512, 768]                1,536\n│    │    └─Dropout: 3-80                               [512, 768]                --\n│    └─EncoderLayer: 2-11                               [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-81               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-82                             [512, 768]                1,536\n│    │    └─Dropout: 3-83                               [512, 768]                --\n│    │    └─Linear: 3-84                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-85                                  [512, 3072]               --\n│    │    └─Linear: 3-86                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-87                             [512, 768]                1,536\n│    │    └─Dropout: 3-88                               [512, 768]                --\n│    └─EncoderLayer: 2-12                               [512, 768]                --\n│    │    └─MultiHeadAttentionLayer: 3-89               [512, 768]                2,359,296\n│    │    └─LayerNorm: 3-90                             [512, 768]                1,536\n│    │    └─Dropout: 3-91                               [512, 768]                --\n│    │    └─Linear: 3-92                                [512, 3072]               2,362,368\n│    │    └─GELU: 3-93                                  [512, 3072]               --\n│    │    └─Linear: 3-94                                [512, 768]                2,360,064\n│    │    └─LayerNorm: 3-95                             [512, 768]                1,536\n│    │    └─Dropout: 3-96                               [512, 768]                --\n=========================================================================================================\nTotal params: 108,854,784\nTrainable params: 108,854,784\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 55.73\n=========================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 427.82\nParams size (MB): 435.42\nEstimated Total Size (MB): 863.24\n========================================================================================================="},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"config = BertConfig.from_pretrained(\"bert-base-uncased\")\nog_model = BertModel.from_pretrained(\"bert-base-uncased\")\nstate_dict = og_model.state_dict()\nmy_bert_model.load_state_dict(state_dict,strict=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T19:21:14.149497Z","iopub.execute_input":"2026-02-05T19:21:14.149926Z","iopub.status.idle":"2026-02-05T19:21:14.834786Z","shell.execute_reply.started":"2026-02-05T19:21:14.149865Z","shell.execute_reply":"2026-02-05T19:21:14.833834Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"_IncompatibleKeys(missing_keys=['token_embedding_layer.weight', 'pos_encoding_layer.weight', 'segment_embedding_layer.weight', 'embedding_sum_layer_norm.weight', 'embedding_sum_layer_norm.bias', 'encoder_layer_stack.0.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.0.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.0.first_layer_norm.weight', 'encoder_layer_stack.0.first_layer_norm.bias', 'encoder_layer_stack.0.ffn_inner_layer.weight', 'encoder_layer_stack.0.ffn_inner_layer.bias', 'encoder_layer_stack.0.ffn_output_layer.weight', 'encoder_layer_stack.0.ffn_output_layer.bias', 'encoder_layer_stack.0.second_layer_norm.weight', 'encoder_layer_stack.0.second_layer_norm.bias', 'encoder_layer_stack.1.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.1.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.1.first_layer_norm.weight', 'encoder_layer_stack.1.first_layer_norm.bias', 'encoder_layer_stack.1.ffn_inner_layer.weight', 'encoder_layer_stack.1.ffn_inner_layer.bias', 'encoder_layer_stack.1.ffn_output_layer.weight', 'encoder_layer_stack.1.ffn_output_layer.bias', 'encoder_layer_stack.1.second_layer_norm.weight', 'encoder_layer_stack.1.second_layer_norm.bias', 'encoder_layer_stack.2.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.2.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.2.first_layer_norm.weight', 'encoder_layer_stack.2.first_layer_norm.bias', 'encoder_layer_stack.2.ffn_inner_layer.weight', 'encoder_layer_stack.2.ffn_inner_layer.bias', 'encoder_layer_stack.2.ffn_output_layer.weight', 'encoder_layer_stack.2.ffn_output_layer.bias', 'encoder_layer_stack.2.second_layer_norm.weight', 'encoder_layer_stack.2.second_layer_norm.bias', 'encoder_layer_stack.3.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.3.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.3.first_layer_norm.weight', 'encoder_layer_stack.3.first_layer_norm.bias', 'encoder_layer_stack.3.ffn_inner_layer.weight', 'encoder_layer_stack.3.ffn_inner_layer.bias', 'encoder_layer_stack.3.ffn_output_layer.weight', 'encoder_layer_stack.3.ffn_output_layer.bias', 'encoder_layer_stack.3.second_layer_norm.weight', 'encoder_layer_stack.3.second_layer_norm.bias', 'encoder_layer_stack.4.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.4.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.4.first_layer_norm.weight', 'encoder_layer_stack.4.first_layer_norm.bias', 'encoder_layer_stack.4.ffn_inner_layer.weight', 'encoder_layer_stack.4.ffn_inner_layer.bias', 'encoder_layer_stack.4.ffn_output_layer.weight', 'encoder_layer_stack.4.ffn_output_layer.bias', 'encoder_layer_stack.4.second_layer_norm.weight', 'encoder_layer_stack.4.second_layer_norm.bias', 'encoder_layer_stack.5.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.5.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.5.first_layer_norm.weight', 'encoder_layer_stack.5.first_layer_norm.bias', 'encoder_layer_stack.5.ffn_inner_layer.weight', 'encoder_layer_stack.5.ffn_inner_layer.bias', 'encoder_layer_stack.5.ffn_output_layer.weight', 'encoder_layer_stack.5.ffn_output_layer.bias', 'encoder_layer_stack.5.second_layer_norm.weight', 'encoder_layer_stack.5.second_layer_norm.bias', 'encoder_layer_stack.6.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.6.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.6.first_layer_norm.weight', 'encoder_layer_stack.6.first_layer_norm.bias', 'encoder_layer_stack.6.ffn_inner_layer.weight', 'encoder_layer_stack.6.ffn_inner_layer.bias', 'encoder_layer_stack.6.ffn_output_layer.weight', 'encoder_layer_stack.6.ffn_output_layer.bias', 'encoder_layer_stack.6.second_layer_norm.weight', 'encoder_layer_stack.6.second_layer_norm.bias', 'encoder_layer_stack.7.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.7.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.7.first_layer_norm.weight', 'encoder_layer_stack.7.first_layer_norm.bias', 'encoder_layer_stack.7.ffn_inner_layer.weight', 'encoder_layer_stack.7.ffn_inner_layer.bias', 'encoder_layer_stack.7.ffn_output_layer.weight', 'encoder_layer_stack.7.ffn_output_layer.bias', 'encoder_layer_stack.7.second_layer_norm.weight', 'encoder_layer_stack.7.second_layer_norm.bias', 'encoder_layer_stack.8.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.8.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.8.first_layer_norm.weight', 'encoder_layer_stack.8.first_layer_norm.bias', 'encoder_layer_stack.8.ffn_inner_layer.weight', 'encoder_layer_stack.8.ffn_inner_layer.bias', 'encoder_layer_stack.8.ffn_output_layer.weight', 'encoder_layer_stack.8.ffn_output_layer.bias', 'encoder_layer_stack.8.second_layer_norm.weight', 'encoder_layer_stack.8.second_layer_norm.bias', 'encoder_layer_stack.9.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.9.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.9.first_layer_norm.weight', 'encoder_layer_stack.9.first_layer_norm.bias', 'encoder_layer_stack.9.ffn_inner_layer.weight', 'encoder_layer_stack.9.ffn_inner_layer.bias', 'encoder_layer_stack.9.ffn_output_layer.weight', 'encoder_layer_stack.9.ffn_output_layer.bias', 'encoder_layer_stack.9.second_layer_norm.weight', 'encoder_layer_stack.9.second_layer_norm.bias', 'encoder_layer_stack.10.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.10.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.10.first_layer_norm.weight', 'encoder_layer_stack.10.first_layer_norm.bias', 'encoder_layer_stack.10.ffn_inner_layer.weight', 'encoder_layer_stack.10.ffn_inner_layer.bias', 'encoder_layer_stack.10.ffn_output_layer.weight', 'encoder_layer_stack.10.ffn_output_layer.bias', 'encoder_layer_stack.10.second_layer_norm.weight', 'encoder_layer_stack.10.second_layer_norm.bias', 'encoder_layer_stack.11.mha_layer.attn_heads.0.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.0.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.0.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.1.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.1.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.1.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.2.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.2.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.2.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.3.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.3.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.3.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.4.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.4.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.4.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.5.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.5.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.5.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.6.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.6.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.6.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.7.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.7.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.7.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.8.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.8.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.8.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.9.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.9.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.9.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.10.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.10.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.10.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.11.query_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.11.key_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.attn_heads.11.value_projection_layer.weight', 'encoder_layer_stack.11.mha_layer.mha_projection_layer.weight', 'encoder_layer_stack.11.first_layer_norm.weight', 'encoder_layer_stack.11.first_layer_norm.bias', 'encoder_layer_stack.11.ffn_inner_layer.weight', 'encoder_layer_stack.11.ffn_inner_layer.bias', 'encoder_layer_stack.11.ffn_output_layer.weight', 'encoder_layer_stack.11.ffn_output_layer.bias', 'encoder_layer_stack.11.second_layer_norm.weight', 'encoder_layer_stack.11.second_layer_norm.bias'], unexpected_keys=['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias'])"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}