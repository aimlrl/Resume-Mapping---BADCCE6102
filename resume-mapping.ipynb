{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2508632,"sourceType":"datasetVersion","datasetId":1519260},{"sourceId":14502473,"sourceType":"datasetVersion","datasetId":9262653}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pdfplumber\n!pip install tiktoken","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-28T04:40:47.963479Z","iopub.execute_input":"2026-01-28T04:40:47.963861Z","iopub.status.idle":"2026-01-28T04:40:58.830791Z","shell.execute_reply.started":"2026-01-28T04:40:47.963831Z","shell.execute_reply":"2026-01-28T04:40:58.829504Z"}},"outputs":[{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting pdfminer.six==20251230 (from pdfplumber)\n  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (46.0.3)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\nDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-5.3.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20251230 pdfplumber-0.11.9 pypdfium2-5.3.0\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.11.12)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pdfplumber\nfrom tqdm import tqdm\nimport tiktoken\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom transformers import BertTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:49:49.343465Z","iopub.execute_input":"2026-01-23T12:49:49.343771Z","iopub.status.idle":"2026-01-23T12:49:58.021945Z","shell.execute_reply.started":"2026-01-23T12:49:49.343744Z","shell.execute_reply":"2026-01-23T12:49:58.020997Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:01.252896Z","iopub.execute_input":"2026-01-23T12:50:01.253669Z","iopub.status.idle":"2026-01-23T12:50:08.827583Z","shell.execute_reply.started":"2026-01-23T12:50:01.253634Z","shell.execute_reply":"2026-01-23T12:50:08.826810Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6690054d038a4827ad5584f3b143b92a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1af83d4d61034f35aea52c7134251f92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4024a0b265844894af70558ac9194fde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f6963c3168744cdb72c20774117ea0a"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def extract_text_from_pdf(pdf_path):\n\n    text = list()\n    with pdfplumber.open(pdf_path) as pdf:\n\n        for page in pdf.pages:\n            page_text = page.extract_text()\n\n            if page_text:\n                text.append(page_text)\n\n    return \"\\n\".join(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:12.123142Z","iopub.execute_input":"2026-01-23T12:50:12.123606Z","iopub.status.idle":"2026-01-23T12:50:12.129154Z","shell.execute_reply.started":"2026-01-23T12:50:12.123580Z","shell.execute_reply":"2026-01-23T12:50:12.128246Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_all_resumes(single_dir_abs_path):\n\n    documents = list()\n\n    for root,_,files in os.walk(single_dir_abs_path):\n        for file in files:\n            if file.lower().endswith(\".pdf\"):\n                pdf_path = os.path.join(root,file)\n                text = extract_text_from_pdf(pdf_path)\n                if text.strip():\n                    documents.append(text)\n    return documents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:13.847170Z","iopub.execute_input":"2026-01-23T12:50:13.847462Z","iopub.status.idle":"2026-01-23T12:50:13.852686Z","shell.execute_reply.started":"2026-01-23T12:50:13.847438Z","shell.execute_reply":"2026-01-23T12:50:13.851734Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"root_dir = \"/kaggle/input/resume-dataset/data/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:15.600455Z","iopub.execute_input":"2026-01-23T12:50:15.600852Z","iopub.status.idle":"2026-01-23T12:50:15.605342Z","shell.execute_reply.started":"2026-01-23T12:50:15.600819Z","shell.execute_reply":"2026-01-23T12:50:15.604262Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def process_resumes_per_category(single_dir):\n    return single_dir, load_all_resumes(os.path.join(root_dir,single_dir))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:16.765348Z","iopub.execute_input":"2026-01-23T12:50:16.765671Z","iopub.status.idle":"2026-01-23T12:50:16.770206Z","shell.execute_reply.started":"2026-01-23T12:50:16.765647Z","shell.execute_reply":"2026-01-23T12:50:16.769320Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\"\"\"\ndata_dict = dict()\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\n    \n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\n        try:\n            single_dir, resumes_raw_text_list = single_pool.result()\n            data_dict[single_dir] = resumes_raw_text_list\n        except Exception as e:\n            print(f\"Error processing {single_dir}: {e}\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:19.106637Z","iopub.execute_input":"2026-01-23T12:50:19.106944Z","iopub.status.idle":"2026-01-23T12:50:19.113986Z","shell.execute_reply.started":"2026-01-23T12:50:19.106919Z","shell.execute_reply":"2026-01-23T12:50:19.112981Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'\\ndata_dict = dict()\\nwith ThreadPoolExecutor(max_workers=os.cpu_count()) as pool:\\n    \\n    parallel_pools = [pool.submit(process_resumes_per_category, single_dir) for single_dir in os.listdir(root_dir)]\\n    for single_pool in tqdm(as_completed(parallel_pools), total=len(parallel_pools)):\\n        try:\\n            single_dir, resumes_raw_text_list = single_pool.result()\\n            data_dict[single_dir] = resumes_raw_text_list\\n        except Exception as e:\\n            print(f\"Error processing {single_dir}: {e}\")\\n'"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"\"\"\"\ngpt_tokenizer_encodings = tiktoken.get_encoding(\"o200k_base\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:20.601347Z","iopub.execute_input":"2026-01-23T12:50:20.602127Z","iopub.status.idle":"2026-01-23T12:50:20.607281Z","shell.execute_reply.started":"2026-01-23T12:50:20.602031Z","shell.execute_reply":"2026-01-23T12:50:20.606439Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'\\ngpt_tokenizer_encodings = tiktoken.get_encoding(\"o200k_base\")\\n'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"\"\"\"\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\n    pickle.dump(data_dict,file_handle)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:22.342177Z","iopub.execute_input":"2026-01-23T12:50:22.342483Z","iopub.status.idle":"2026-01-23T12:50:22.348437Z","shell.execute_reply.started":"2026-01-23T12:50:22.342460Z","shell.execute_reply":"2026-01-23T12:50:22.347602Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\\nwith open(\"data_dict.pkl\",\"wb\") as file_handle:\\n    pickle.dump(data_dict,file_handle)\\n'"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"with open(\"/kaggle/input/proprocessed-data-pickle-file/data_dict.pkl\",\"rb\") as file_handle:\n    data_dict = pickle.load(file_handle)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:28.216940Z","iopub.execute_input":"2026-01-23T12:50:28.217221Z","iopub.status.idle":"2026-01-23T12:50:28.361213Z","shell.execute_reply.started":"2026-01-23T12:50:28.217195Z","shell.execute_reply":"2026-01-23T12:50:28.360385Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"encoded_data_dict = {\"Resume Encoded Text\":[], \"Suitable Job\":[]}\nrow_idx = 0\nmax_len = 0\n\nfor k,v in data_dict.items():\n    for resume_text in v:\n\n        encoded_resume_text = tokenizer.tokenize(resume_text)\n        encoded_resume_text = [\"[CLS]\"] + encoded_resume_text \n        encoded_data_dict[\"Resume Encoded Text\"].append(encoded_resume_text)\n        encoded_data_dict[\"Suitable Job\"].append(k)\n\n        if len(encoded_resume_text)+1 > max_len:\n            max_len = len(encoded_resume_text)+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:50:29.941190Z","iopub.execute_input":"2026-01-23T12:50:29.941537Z","iopub.status.idle":"2026-01-23T12:51:02.780107Z","shell.execute_reply.started":"2026-01-23T12:50:29.941494Z","shell.execute_reply":"2026-01-23T12:51:02.779156Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"bert_base_context_len = 512\nmax_len = max_len - (max_len % bert_base_context_len)\nprint(max_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:51:23.261593Z","iopub.execute_input":"2026-01-23T12:51:23.261922Z","iopub.status.idle":"2026-01-23T12:51:23.267941Z","shell.execute_reply.started":"2026-01-23T12:51:23.261894Z","shell.execute_reply":"2026-01-23T12:51:23.266837Z"}},"outputs":[{"name":"stdout","text":"6144\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"for idx, encoded_resume_text in enumerate(encoded_data_dict[\"Resume Encoded Text\"]):\n    encoded_data_dict[\"Resume Encoded Text\"][idx] = encoded_resume_text + [0]*((max_len-1)-len(encoded_resume_text)) + [\"[SEP]\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:51:31.415558Z","iopub.execute_input":"2026-01-23T12:51:31.415965Z","iopub.status.idle":"2026-01-23T12:51:31.614957Z","shell.execute_reply.started":"2026-01-23T12:51:31.415837Z","shell.execute_reply":"2026-01-23T12:51:31.614093Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data = pd.DataFrame(data=encoded_data_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:51:33.623161Z","iopub.execute_input":"2026-01-23T12:51:33.623882Z","iopub.status.idle":"2026-01-23T12:51:33.634977Z","shell.execute_reply.started":"2026-01-23T12:51:33.623849Z","shell.execute_reply":"2026-01-23T12:51:33.634109Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:51:34.064753Z","iopub.execute_input":"2026-01-23T12:51:34.065053Z","iopub.status.idle":"2026-01-23T12:51:34.174692Z","shell.execute_reply.started":"2026-01-23T12:51:34.065029Z","shell.execute_reply":"2026-01-23T12:51:34.173601Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                 Resume Encoded Text Suitable Job\n0  [[CLS], pre, -, press, graphic, designer, summ...     DESIGNER\n1  [[CLS], principle, designer, /, owner, profess...     DESIGNER\n2  [[CLS], project, designer, summary, team, -, o...     DESIGNER\n3  [[CLS], interior, designer, summary, a, result...     DESIGNER\n4  [[CLS], presentation, designer, summary, custo...     DESIGNER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Encoded Text</th>\n      <th>Suitable Job</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[CLS], pre, -, press, graphic, designer, summ...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[CLS], principle, designer, /, owner, profess...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[CLS], project, designer, summary, team, -, o...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[CLS], interior, designer, summary, a, result...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[CLS], presentation, designer, summary, custo...</td>\n      <td>DESIGNER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"data[\"Resume Encoded Text\"] = data[\"Resume Encoded Text\"].apply(lambda x: tokenizer.convert_tokens_to_ids(x))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:51:36.867212Z","iopub.execute_input":"2026-01-23T12:51:36.867558Z","iopub.status.idle":"2026-01-23T12:52:05.442614Z","shell.execute_reply.started":"2026-01-23T12:51:36.867533Z","shell.execute_reply":"2026-01-23T12:52:05.441320Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:08.864558Z","iopub.execute_input":"2026-01-23T12:52:08.864829Z","iopub.status.idle":"2026-01-23T12:52:08.884369Z","shell.execute_reply.started":"2026-01-23T12:52:08.864806Z","shell.execute_reply":"2026-01-23T12:52:08.883581Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                                    Resume Encoded Text Suitable Job\n0     [101, 3653, 1011, 2811, 8425, 5859, 12654, 554...     DESIGNER\n1     [101, 6958, 5859, 1013, 3954, 2658, 12654, 459...     DESIGNER\n2     [101, 2622, 5859, 12654, 2136, 1011, 8048, 199...     DESIGNER\n3     [101, 4592, 5859, 12654, 1037, 3463, 8048, 585...     DESIGNER\n4     [101, 8312, 5859, 12654, 8013, 2326, 1998, 702...     DESIGNER\n...                                                 ...          ...\n2478  [101, 4007, 3992, 6337, 5281, 4007, 3992, 2236...         ARTS\n2479  [101, 5957, 16661, 2658, 6337, 29454, 29206, 2...         ARTS\n2480  [101, 5964, 1010, 6619, 1998, 7891, 2394, 3836...         ARTS\n2481  [101, 3772, 3694, 1018, 8013, 1013, 4435, 6337...         ARTS\n2482  [101, 2472, 1997, 4258, 11637, 3968, 4179, 101...         ARTS\n\n[2483 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Encoded Text</th>\n      <th>Suitable Job</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 3653, 1011, 2811, 8425, 5859, 12654, 554...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 6958, 5859, 1013, 3954, 2658, 12654, 459...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 2622, 5859, 12654, 2136, 1011, 8048, 199...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 4592, 5859, 12654, 1037, 3463, 8048, 585...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 8312, 5859, 12654, 8013, 2326, 1998, 702...</td>\n      <td>DESIGNER</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2478</th>\n      <td>[101, 4007, 3992, 6337, 5281, 4007, 3992, 2236...</td>\n      <td>ARTS</td>\n    </tr>\n    <tr>\n      <th>2479</th>\n      <td>[101, 5957, 16661, 2658, 6337, 29454, 29206, 2...</td>\n      <td>ARTS</td>\n    </tr>\n    <tr>\n      <th>2480</th>\n      <td>[101, 5964, 1010, 6619, 1998, 7891, 2394, 3836...</td>\n      <td>ARTS</td>\n    </tr>\n    <tr>\n      <th>2481</th>\n      <td>[101, 3772, 3694, 1018, 8013, 1013, 4435, 6337...</td>\n      <td>ARTS</td>\n    </tr>\n    <tr>\n      <th>2482</th>\n      <td>[101, 2472, 1997, 4258, 11637, 3968, 4179, 101...</td>\n      <td>ARTS</td>\n    </tr>\n  </tbody>\n</table>\n<p>2483 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"shuffled_data = data.iloc[np.random.choice(np.arange(0,data.shape[0]),size=(data.shape[0],),replace=False)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:11.747145Z","iopub.execute_input":"2026-01-23T12:52:11.747419Z","iopub.status.idle":"2026-01-23T12:52:11.753050Z","shell.execute_reply.started":"2026-01-23T12:52:11.747396Z","shell.execute_reply":"2026-01-23T12:52:11.752207Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"shuffled_data.reset_index(inplace=True,drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:13.992582Z","iopub.execute_input":"2026-01-23T12:52:13.992884Z","iopub.status.idle":"2026-01-23T12:52:13.997199Z","shell.execute_reply.started":"2026-01-23T12:52:13.992852Z","shell.execute_reply":"2026-01-23T12:52:13.996356Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"shuffled_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:16.049412Z","iopub.execute_input":"2026-01-23T12:52:16.049740Z","iopub.status.idle":"2026-01-23T12:52:16.071117Z","shell.execute_reply.started":"2026-01-23T12:52:16.049715Z","shell.execute_reply":"2026-01-23T12:52:16.069613Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                    Resume Encoded Text  \\\n0     [101, 2592, 2974, 8325, 12654, 2592, 3036, 129...   \n1     [101, 2449, 2458, 8930, 2476, 3579, 2969, 1175...   \n2     [101, 3218, 3208, 3237, 12654, 6143, 1010, 143...   \n3     [101, 2449, 2458, 2415, 3208, 2658, 12654, 879...   \n4     [101, 3237, 10026, 2658, 12654, 2000, 3693, 20...   \n...                                                 ...   \n2478  [101, 2449, 2458, 3237, 2658, 12654, 3811, 127...   \n2479  [101, 10026, 9450, 2658, 12654, 27060, 10026, ...   \n2480  [101, 9871, 13024, 2121, 11637, 7513, 2436, 76...   \n2481  [101, 2436, 3208, 11637, 7513, 2436, 2591, 286...   \n2482  [101, 13024, 2121, 2476, 19184, 9677, 1998, 26...   \n\n                Suitable Job  \n0     INFORMATION-TECHNOLOGY  \n1       BUSINESS-DEVELOPMENT  \n2     INFORMATION-TECHNOLOGY  \n3       BUSINESS-DEVELOPMENT  \n4                       CHEF  \n...                      ...  \n2478    BUSINESS-DEVELOPMENT  \n2479                    CHEF  \n2480              HEALTHCARE  \n2481                 APPAREL  \n2482              AUTOMOBILE  \n\n[2483 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Resume Encoded Text</th>\n      <th>Suitable Job</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 2592, 2974, 8325, 12654, 2592, 3036, 129...</td>\n      <td>INFORMATION-TECHNOLOGY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 2449, 2458, 8930, 2476, 3579, 2969, 1175...</td>\n      <td>BUSINESS-DEVELOPMENT</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 3218, 3208, 3237, 12654, 6143, 1010, 143...</td>\n      <td>INFORMATION-TECHNOLOGY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 2449, 2458, 2415, 3208, 2658, 12654, 879...</td>\n      <td>BUSINESS-DEVELOPMENT</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 3237, 10026, 2658, 12654, 2000, 3693, 20...</td>\n      <td>CHEF</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2478</th>\n      <td>[101, 2449, 2458, 3237, 2658, 12654, 3811, 127...</td>\n      <td>BUSINESS-DEVELOPMENT</td>\n    </tr>\n    <tr>\n      <th>2479</th>\n      <td>[101, 10026, 9450, 2658, 12654, 27060, 10026, ...</td>\n      <td>CHEF</td>\n    </tr>\n    <tr>\n      <th>2480</th>\n      <td>[101, 9871, 13024, 2121, 11637, 7513, 2436, 76...</td>\n      <td>HEALTHCARE</td>\n    </tr>\n    <tr>\n      <th>2481</th>\n      <td>[101, 2436, 3208, 11637, 7513, 2436, 2591, 286...</td>\n      <td>APPAREL</td>\n    </tr>\n    <tr>\n      <th>2482</th>\n      <td>[101, 13024, 2121, 2476, 19184, 9677, 1998, 26...</td>\n      <td>AUTOMOBILE</td>\n    </tr>\n  </tbody>\n</table>\n<p>2483 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"labels2idx = dict(zip(data_dict.keys(),range(0,len(data_dict.keys()))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:23.218069Z","iopub.execute_input":"2026-01-23T12:52:23.218389Z","iopub.status.idle":"2026-01-23T12:52:23.222959Z","shell.execute_reply.started":"2026-01-23T12:52:23.218364Z","shell.execute_reply":"2026-01-23T12:52:23.221681Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"training_data = data.iloc[0:int(0.7*data.shape[0])]\ntesting_data = data.iloc[int(0.7*data.shape[0]):]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:25.880882Z","iopub.execute_input":"2026-01-23T12:52:25.881164Z","iopub.status.idle":"2026-01-23T12:52:25.886900Z","shell.execute_reply.started":"2026-01-23T12:52:25.881141Z","shell.execute_reply":"2026-01-23T12:52:25.885376Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"len(training_data.iloc[0,0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:28.038566Z","iopub.execute_input":"2026-01-23T12:52:28.038838Z","iopub.status.idle":"2026-01-23T12:52:28.044560Z","shell.execute_reply.started":"2026-01-23T12:52:28.038814Z","shell.execute_reply":"2026-01-23T12:52:28.043790Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"6144"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def training_data_generator(mb_size=79):\n\n    for i in range(training_data.shape[0]//mb_size):\n\n        X_mb = np.array(training_data.iloc[i*mb_size:(i+1)*mb_size,0])\n        y_mb = np.array(training_data.iloc[i*mb_size:(i+1)*mb_size,1])\n\n        yield X_mb, y_mb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:52:31.270699Z","iopub.execute_input":"2026-01-23T12:52:31.270991Z","iopub.status.idle":"2026-01-23T12:52:31.290664Z","shell.execute_reply.started":"2026-01-23T12:52:31.270951Z","shell.execute_reply":"2026-01-23T12:52:31.289795Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"class SingleAttentionHead(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,sha_dim,masked):\n        super().__init__()\n\n        self.sha_dim = sha_dim\n        self.masked = masked\n\n        self.query_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.key_projection_layer = torch.nn.Linear(in_features=query_key_embedding_dim,\n                                                   out_features=sha_dim,bias=False)\n        self.value_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                     out_features=sha_dim,bias=False)\n        self.softmax_activation = torch.nn.Softmax(dim=1)\n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        projected_query = self.query_projection_layer(query_embedding)\n        projected_key = self.key_projection_layer(key_embedding)\n        projected_value = self.value_projection_layer(value_embedding)\n\n        query_key_similarity_search = torch.matmul(projected_query,torch.transpose(projected_key,1,0))/torch.sqrt(torch.tensor([self.sha_dim]))\n\n        if self.masked:\n            query_key_similarity_search = torch.tril(query_key_similarity_search,0)\n            \n        query_key_soft_search = self.softmax_activation(query_key_similarity_search)\n        weighted_attn_embedding = torch.matmul(query_key_soft_search,projected_value)\n\n        return weighted_attn_embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:06:20.815451Z","iopub.execute_input":"2026-01-23T17:06:20.816245Z","iopub.status.idle":"2026-01-23T17:06:20.822988Z","shell.execute_reply.started":"2026-01-23T17:06:20.816215Z","shell.execute_reply":"2026-01-23T17:06:20.822144Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"class MultiHeadAttentionLayer(torch.nn.Module):\n\n    def __init__(self,query_key_embedding_dim,value_embedding_dim,num_attn_heads,masked):\n        super().__init__()\n        \n        sha_dim = value_embedding_dim//num_attn_heads\n        self.attn_heads = list()\n        \n        for _ in range(num_attn_heads):\n            self.attn_heads.append(SingleAttentionHead(query_key_embedding_dim,value_embedding_dim,\n                                       sha_dim,masked))\n\n        self.mha_projection_layer = torch.nn.Linear(in_features=value_embedding_dim,\n                                                   out_features=value_embedding_dim,bias=False)\n\n    def forward(self,query_embedding,key_embedding,value_embedding):\n\n        attn_heads_weighted_embeddings = list()\n\n        for single_attn_head in self.attn_heads:\n            attn_heads_weighted_embeddings.append(single_attn_head(query_embedding,key_embedding,\n                                                                  value_embedding))\n\n        mha_concatenated_embeddings = torch.cat(attn_heads_weighted_embeddings,dim=1)\n        mha_output = self.mha_projection_layer(mha_concatenated_embeddings)\n        \n        return mha_output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:07:24.675189Z","iopub.execute_input":"2026-01-23T17:07:24.675494Z","iopub.status.idle":"2026-01-23T17:07:24.681899Z","shell.execute_reply.started":"2026-01-23T17:07:24.675470Z","shell.execute_reply":"2026-01-23T17:07:24.681124Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"class EncoderLayer(torch.nn.Module):\n\n    def __init__(self,input_embedding_dim,num_attn_heads):\n        super().__init__()\n\n        self.mha_layer = MultiHeadAttentionLayer(input_embedding_dim,input_embedding_dim,\n                                                num_attn_heads,False)\n        self.layer_norm_1 = torch.nn.LayerNorm(input_embedding_dim)\n        self.ffn_inner_layer = torch.nn.Linear(in_features=input_embedding_dim,\n                                              out_features=4*input_embedding_dim)\n        self.ffn_output_layer = torch.nn.Linear(in_features=4*input_embedding_dim,\n                                               out_features=input_embedding_dim)\n        self.layer_norm_2 = torch.nn.LayerNorm(input_embedding_dim)\n\n    \n    def forward(self,input_embedding):\n\n        mha_layer_out = self.mha_layer(input_embedding,input_embedding,input_embedding)\n        layer_norm1_out = self.layer_norm_1(input_embedding+mha_layer_out)\n        higher_dim_projection = self.ffn_inner_layer(layer_norm1_out)\n        ffn_out = self.ffn_output_layer(higher_dim_projection)\n        encoder_layer_out = self.layer_norm_2(ffn_out)\n\n        return encoder_layer_out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:31:03.510330Z","iopub.execute_input":"2026-01-23T17:31:03.510639Z","iopub.status.idle":"2026-01-23T17:31:03.526856Z","shell.execute_reply.started":"2026-01-23T17:31:03.510614Z","shell.execute_reply":"2026-01-23T17:31:03.525960Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"class BERT(torch.nn.Module):\n\n    def __init__(self,vocab_size,max_context_len,model_dim,num_encoder_layers,\n                 num_attn_heads,num_classes,model_context_len):\n        super().__init__()\n\n        \n        self.model_context_len = model_context_len\n        self.embedding_layer = torch.nn.Embedding(num_embeddings=vocab_size,\n                                                  embedding_dim=model_dim)\n        self.pos_encoding_layer = torch.nn.Embedding(num_embeddings=max_context_len,\n                                                    embedding_dim=model_dim)\n        self.encoder_layer_stack = list()\n\n        for _ in range(num_encoder_layers):\n            self.encoder_layer_stack.append(EncoderLayer(model_dim,num_attn_heads))\n\n        self.classification_head = torch.nn.Linear(in_features=model_dim,out_features=num_classes)\n        self.classification_head_activation = torch.nn.Softmax(dim=1)\n\n\n    def forward(self,X):\n\n        token_embedding = self.embedding_layer(X)\n        position_ids = torch.arange(start=0,end=max_context_len)\n        position_ids = position_ids.view(max_context_len//self.model_context_len,\n                                         self.model_context_len)\n        pos_encoding = self.pos_encoding_layer(position_ids)\n        input_embedding = token_embedding + pos_encoding\n\n        for single_encoding_layer in self.encoder_layer_stack:\n            output_embedding = single_encoding_layer(input_embedding)\n            input_embedding = output_embedding\n\n        encoder_out = self.classification_head_activation(self.classification_head(output_embedding[:,0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T18:47:09.908944Z","iopub.execute_input":"2026-01-23T18:47:09.909288Z","iopub.status.idle":"2026-01-23T18:47:09.917813Z","shell.execute_reply.started":"2026-01-23T18:47:09.909263Z","shell.execute_reply":"2026-01-23T18:47:09.916585Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}